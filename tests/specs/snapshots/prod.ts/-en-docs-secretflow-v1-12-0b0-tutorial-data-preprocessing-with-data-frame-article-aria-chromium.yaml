- article:
  - heading "Data Preprocessing with DataFrame" [level=1]:
    - link "Direct link to Data Preprocessing with DataFrame":
      - /url: "#Data-Preprocessing-with-DataFrame"
  - blockquote:
    - paragraph:
      - text: The following codes are demos only. Itâ€™s
      - strong: NOT for production
      - text: due to system security concerns, please
      - strong: DO NOT
      - text: use it directly in production.
  - paragraph:
    - text: It is recommended to use
    - link "jupyter":
      - /url: https://jupyter.org/
    - text: to run this tutorial.
  - paragraph: Secretflow provides a variety of preprocessing tools to process data.
  - heading "Preparation" [level=2]:
    - link "Direct link to Preparation":
      - /url: "#Preparation"
  - paragraph: Initialize secretflow and create two parties alice and bob.
  - blockquote:
    - paragraph:
      - text: ðŸ’¡ Before using preprocessing, you may need to get to know secretflowâ€™s
      - link "DataFrame":
        - /url: /en/docs/secretflow/v1.12.0b0/user_guide/preprocessing/DataFrame
      - text: .
  - code: "In [1]:"
  - button "Copy":
    - img "copy"
  - code: python
  - code: "import secretflow as sf # Check the version of your SecretFlow print('The version of SecretFlow: {}'.format(sf.__version__)) # In case you have a running secretflow runtime already. sf.shutdown() sf.init(['alice', 'bob'], address='local') alice = sf.PYU('alice') bob = sf.PYU('bob')"
  - code: Out
  - text: "The version of SecretFlow: 1.2.0.dev20231007"
  - heading "Data Preparation" [level=2]:
    - link "Direct link to Data Preparation":
      - /url: "#Data-Preparation"
  - paragraph:
    - text: Here we use
    - link "iris":
      - /url: https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_iris.html
    - text: as example data.
  - code: "In [2]:"
  - button "Copy":
    - img "copy"
  - code: python
  - code: "/import pandas as pd from sklearn\\.datasets import load_iris iris = load_iris\\(as_frame=True\\) data = pd\\.concat\\(\\[iris\\.data, iris\\.target\\], axis=1\\) # In order to facilitate the subsequent display, # here we first set some data to None\\. data\\.iloc\\[1, 1\\] = None data\\.iloc\\[\\d+, 1\\] = None # Restore target to its original name\\. data\\['target'\\] = data\\['target'\\]\\.map\\(\\{0: 'setosa', 1: 'versicolor', 2: 'virginica'\\}\\) data/"
  - code: "Out [2]:"
  - table:
    - rowgroup:
      - row "sepal length (cm) sepal width (cm) petal length (cm) petal width (cm) target":
        - cell
        - cell "sepal length (cm)"
        - cell "sepal width (cm)"
        - cell "petal length (cm)"
        - cell "petal width (cm)"
        - cell "target"
    - rowgroup:
      - row "0 5.1 3.5 1.4 0.2 setosa":
        - cell "0"
        - cell "5.1"
        - cell "3.5"
        - cell "1.4"
        - cell "0.2"
        - cell "setosa"
      - row "1 4.9 NaN 1.4 0.2 setosa":
        - cell "1"
        - cell "4.9"
        - cell "NaN"
        - cell "1.4"
        - cell "0.2"
        - cell "setosa"
      - row "2 4.7 3.2 1.3 0.2 setosa":
        - cell "2"
        - cell "4.7"
        - cell "3.2"
        - cell "1.3"
        - cell "0.2"
        - cell "setosa"
      - row "3 4.6 3.1 1.5 0.2 setosa":
        - cell "3"
        - cell "4.6"
        - cell "3.1"
        - cell "1.5"
        - cell "0.2"
        - cell "setosa"
      - row "4 5.0 3.6 1.4 0.2 setosa":
        - cell "4"
        - cell "5.0"
        - cell "3.6"
        - cell "1.4"
        - cell "0.2"
        - cell "setosa"
      - row "... ... ... ... ... ...":
        - cell "..."
        - cell "..."
        - cell "..."
        - cell "..."
        - cell "..."
        - cell "..."
      - row /\d+ 6\.7 3\.0 5\.2 2\.3 virginica/:
        - cell /\d+/
        - cell "6.7"
        - cell "3.0"
        - cell "5.2"
        - cell "2.3"
        - cell "virginica"
      - row /\d+ 6\.3 2\.5 5\.0 1\.9 virginica/:
        - cell /\d+/
        - cell "6.3"
        - cell "2.5"
        - cell "5.0"
        - cell "1.9"
        - cell "virginica"
      - row /\d+ 6\.5 3\.0 5\.2 2\.0 virginica/:
        - cell /\d+/
        - cell "6.5"
        - cell "3.0"
        - cell "5.2"
        - cell "2.0"
        - cell "virginica"
      - row /\d+ 6\.2 3\.4 5\.4 2\.3 virginica/:
        - cell /\d+/
        - cell "6.2"
        - cell "3.4"
        - cell "5.4"
        - cell "2.3"
        - cell "virginica"
      - row /\d+ 5\.9 3\.0 5\.1 1\.8 virginica/:
        - cell /\d+/
        - cell "5.9"
        - cell "3.0"
        - cell "5.1"
        - cell "1.8"
        - cell "virginica"
  - paragraph: /\d+ rows Ã— 5 columns/
  - paragraph: Create a vertical partitioned DataFrame.
  - code: "In [3]:"
  - button "Copy":
    - img "copy"
  - code: python
  - code: "import tempfile from secretflow.data.vertical import read_csv as v_read_csv # Vertical partitioning. v_alice, v_bob = data.iloc[:, :2], data.iloc[:, 2:] # Save to temprary files. _, alice_path = tempfile.mkstemp() _, bob_path = tempfile.mkstemp() v_alice.to_csv(alice_path, index=False) v_bob.to_csv(bob_path, index=False) df = v_read_csv({alice: alice_path, bob: bob_path})"
  - paragraph: You can also create a horizontal partitioned DataFrame, which works the same with vertical partitioning for subsequent steps.
  - code: "In [4]:"
  - button "Copy":
    - img "copy"
  - code: python
  - code: "/# from secretflow\\.data\\.horizontal import read_csv as h_read_csv # from secretflow\\.security\\.aggregation import PlainAggregator # from secretflow\\.security\\.compare import PlainComparator # # Horizontal partitioning\\. # h_alice, h_bob = data\\.iloc\\[:\\d+, :\\], data\\.iloc\\[\\d+:, :\\] # # Save to temorary files\\. # _, h_alice_path = tempfile\\.mkstemp\\(\\) # _, h_bob_path = tempfile\\.mkstemp\\(\\) # h_alice\\.to_csv\\(h_alice_path, index=False\\) # h_bob\\.to_csv\\(h_bob_path, index=False\\) # df = h_read_csv\\( # \\{alice: h_alice_path, bob: h_bob_path\\}, # aggregator=PlainAggregator\\(alice\\), # comparator=PlainComparator\\(alice\\), # \\)/"
  - heading "Preprocessing" [level=2]:
    - link "Direct link to Preprocessing":
      - /url: "#Preprocessing"
  - paragraph: Secretflow provides missing value filling, standardization, categorical features encoding, discretization .etc, which are similar to sklearnâ€™s preprocessing.
  - heading "Missing value filling" [level=3]:
    - link "Direct link to Missing value filling":
      - /url: "#Missing-value-filling"
  - paragraph: DataFrame provides the fillna method, which can fill in missing values in the same way as pandas.
  - code: "In [5]:"
  - button "Copy":
    - img "copy"
  - code: python
  - code: "# Before filling, the sepal width (cm) is missing in two positions. df.count()['sepal width (cm)']"
  - code: "Out [5]:"
  - text: /\d+/
  - code: "In [6]:"
  - button "Copy":
    - img "copy"
  - code: python
  - code: "/# Fill sepal width \\(cm\\) with \\d+\\. df\\.fillna\\(value=\\{'sepal width \\(cm\\)': \\d+\\}\\)\\.count\\(\\)\\['sepal width \\(cm\\)'\\]/"
  - code: "Out [6]:"
  - text: /\d+/
  - heading "Standardization" [level=3]:
    - link "Direct link to Standardization":
      - /url: "#Standardization"
  - heading "Scaling features to a range" [level=4]:
    - link "Direct link to Scaling features to a range":
      - /url: "#Scaling-features-to-a-range"
  - paragraph:
    - text: Secretflow provides
    - code: MinMaxScaler
    - text: for scaling features to lie between a given minimum and maximum value. The input and output of MinMaxScaler are both
    - code: DataFrame
    - text: .
  - paragraph:
    - text: Here is an exmaple to scale
    - code: sepal length (cm)
    - text: to the [0, 1] range.
  - code: "In [7]:"
  - button "Copy":
    - img "copy"
  - code: python
  - code: "from secretflow.preprocessing import MinMaxScaler scaler = MinMaxScaler() scaled_sepal_len = scaler.fit_transform(df['sepal length (cm)']) print('Min: ', scaled_sepal_len.min()) print('Max: ', scaled_sepal_len.max())"
  - code: Out
  - text: "Min: sepal length (cm) 0.0 dtype: float64 Max: sepal length (cm) 1.0 dtype: float64"
  - heading "Variance scaling" [level=4]:
    - link "Direct link to Variance scaling":
      - /url: "#Variance-scaling"
  - paragraph:
    - text: Secretflow provides
    - code: StandardScaler
    - text: for variance scaling. The input and output of StandardScaler are both DataFrames.
  - paragraph:
    - text: Here is an exmaple to scale
    - code: sepal length (cm)
    - text: to unit variance.
  - code: "In [8]:"
  - button "Copy":
    - img "copy"
  - code: python
  - code: "from secretflow.preprocessing import StandardScaler scaler = StandardScaler() scaled_sepal_len = scaler.fit_transform(df['sepal length (cm)']) print('Min: ', scaled_sepal_len.min()) print('Max: ', scaled_sepal_len.max())"
  - code: Out
  - text: "/Min: sepal length \\(cm\\) -\\d+\\.\\d+ dtype: float64 Max: sepal length \\(cm\\) \\d+\\.\\d+ dtype: float64/"
  - heading "Encoding categorical features" [level=3]:
    - link "Direct link to Encoding categorical features":
      - /url: "#Encoding-categorical-features"
  - heading "OneHot encoding" [level=4]:
    - link "Direct link to OneHot encoding":
      - /url: "#OneHot-encoding"
  - paragraph:
    - text: Secretflow provides
    - code: OneHotEncoder
    - text: for OneHot encoding. The input and output of OneHotEncoder are
    - code: DataFrame
    - text: .
  - paragraph: Here is an example to encode target with onehot.
  - code: "In [9]:"
  - button "Copy":
    - img "copy"
  - code: python
  - code: "from secretflow.preprocessing import OneHotEncoder onehot_encoder = OneHotEncoder() onehot_target = onehot_encoder.fit_transform(df['target']) print('Columns: ', onehot_target.columns) print('Min: \\n', onehot_target.min()) print('Max: \\n', onehot_target.max())"
  - code: Out
  - text: "Columns: ['target_setosa', 'target_versicolor', 'target_virginica'] Min: target_setosa 0.0 target_versicolor 0.0 target_virginica 0.0 dtype: float64 Max: target_setosa 1.0 target_versicolor 1.0 target_virginica 1.0 dtype: float64"
  - heading "Label encoding" [level=4]:
    - link "Direct link to Label encoding":
      - /url: "#Label-encoding"
  - paragraph:
    - text: secretflow provides
    - code: LabelEncoder
    - text: for encoding target labels with value between 0 and n_classes-1. The input and output of LabelEncoder are
    - code: DataFrame
    - text: .
  - paragraph: Here is an example to encode target to [0, n_classes-1].
  - code: /In \[\d+\]:/
  - button "Copy":
    - img "copy"
  - code: python
  - code: "from secretflow.preprocessing import LabelEncoder label_encoder = LabelEncoder() encoded_label = label_encoder.fit_transform(df['target']) print('Columns: ', encoded_label.columns) print('Min: \\n', encoded_label.min()) print('Max: \\n', encoded_label.max())"
  - code: Out
  - text: "Columns: ['target'] Min: target 0 dtype: int64 Max: target 2 dtype: int64"
  - heading "Discretization" [level=3]:
    - link "Direct link to Discretization":
      - /url: "#Discretization"
  - paragraph:
    - text: SecretFlow provides
    - code: KBinsDiscretizer
    - text: for partitioning continuous features into discrete values. The input and output of KBinsDiscretizer are both
    - code: DataFrame
    - text: .
  - paragraph:
    - text: Here is an example to partition
    - code: petal length (cm)
    - text: to 5 bins.
  - code: /In \[\d+\]:/
  - button "Copy":
    - img "copy"
  - code: python
  - code: "from secretflow.preprocessing import KBinsDiscretizer estimator = KBinsDiscretizer(n_bins=5) binned_petal_len = estimator.fit_transform(df['petal length (cm)']) print('Min: \\n', binned_petal_len.min()) print('Max: \\n', binned_petal_len.max())"
  - code: Out
  - text: "Min: petal length (cm) 0.0 dtype: float64 Max: petal length (cm) 4.0 dtype: float64"
  - heading "WOE encoding" [level=4]:
    - link "Direct link to WOE encoding":
      - /url: "#WOE-encoding"
  - paragraph:
    - text: secretflow provides
    - code: VertWoeBinning
    - text: to bin the features into buckets by quantile or chimerge method, and calculate the woe value and iv value in each bucket. And
    - code: VertBinSubstitution
    - text: can substitute the features with the woe value.
  - paragraph: Here is an example to encode features to woe.
  - code: /In \[\d+\]:/
  - button "Copy":
    - img "copy"
  - code: python
  - code: "/# woe binning use SPU or HEU device to protect label spu = sf\\.SPU\\(sf\\.utils\\.testing\\.cluster_def\\(\\['alice', 'bob'\\]\\)\\) # Only support binary classification label dataset for now\\. # use linear dataset as example from secretflow\\.utils\\.simulation\\.datasets import load_linear vdf = load_linear\\(parts=\\{alice: \\(1, 4\\), bob: \\(\\d+, \\d+\\)\\}\\) print\\(f\"orig ds in alice:\\\\n \\{sf\\.reveal\\(vdf\\.partitions\\[alice\\]\\.data\\)\\}\"\\) print\\(f\"orig ds in bob:\\\\n \\{sf\\.reveal\\(vdf\\.partitions\\[bob\\]\\.data\\)\\}\"\\) from secretflow\\.preprocessing\\.binning\\.vert_woe_binning import VertWoeBinning binning = VertWoeBinning\\(spu\\) bin_rules = binning\\.binning\\( vdf, binning_method=\"quantile\", bin_num=5, bin_names=\\{alice: \\[\"x1\", \"x2\", \"x3\"\\], bob: \\[\"x18\", \"x19\", \"x20\"\\]\\}, label_name=\"y\", \\) print\\(f\"bin_rules for alice:\\\\n \\{sf\\.reveal\\(bin_rules\\[alice\\]\\)\\}\"\\) print\\(f\"bin_rules for bob:\\\\n \\{sf\\.reveal\\(bin_rules\\[bob\\]\\)\\}\"\\) from secretflow\\.preprocessing\\.binning\\.vert_bin_substitution import VertBinSubstitution woe_sub = VertBinSubstitution\\(\\) sub_data = woe_sub\\.substitution\\(vdf, bin_rules\\) print\\(f\"substituted ds in alice:\\\\n \\{sf\\.reveal\\(sub_data\\.partitions\\[alice\\]\\.data\\)\\}\"\\) print\\(f\"substituted ds in bob:\\\\n \\{sf\\.reveal\\(sub_data\\.partitions\\[bob\\]\\.data\\)\\}\"\\)/"
  - code: Out
  - text: "/orig ds in alice: x1 x2 x3 0 -\\d+\\.\\d+ \\d+\\.\\d+ -\\d+\\.\\d+ 1 -\\d+\\.\\d+ \\d+\\.\\d+ -\\d+\\.\\d+ 2 \\d+\\.\\d+ -\\d+\\.\\d+ -\\d+\\.\\d+ 3 -\\d+\\.\\d+ \\d+\\.\\d+ \\d+\\.\\d+ 4 -\\d+\\.\\d+ \\d+\\.\\d+ \\d+\\.\\d+ \\.\\.\\. \\.\\.\\. \\.\\.\\. \\.\\.\\. \\d+ -\\d+\\.\\d+ -\\d+\\.\\d+ \\d+\\.\\d+ \\d+ \\d+\\.\\d+ \\d+\\.\\d+ -\\d+\\.\\d+ \\d+ -\\d+\\.\\d+ \\d+\\.\\d+ -\\d+\\.\\d+ \\d+ \\d+\\.\\d+ -\\d+\\.\\d+ \\d+\\.\\d+ \\d+ -\\d+\\.\\d+ -\\d+\\.\\d+ \\d+\\.\\d+ \\[\\d+ rows x 3 columns\\] orig ds in bob: x18 x19 x20 y 0 \\d+\\.\\d+ \\d+\\.\\d+ \\d+\\.\\d+ 1 1 \\d+\\.\\d+ \\d+\\.\\d+ \\d+\\.\\d+ 1 2 \\d+\\.\\d+ -\\d+\\.\\d+ \\d+\\.\\d+ 0 3 -\\d+\\.\\d+ \\d+\\.\\d+ \\d+\\.\\d+ 1 4 -\\d+\\.\\d+ \\d+\\.\\d+ -\\d+\\.\\d+ 1 \\.\\.\\. \\.\\.\\. \\.\\.\\. \\.\\.\\. \\.\\. \\d+ -\\d+\\.\\d+ \\d+\\.\\d+ \\d+\\.\\d+ 1 \\d+ -\\d+\\.\\d+ -\\d+\\.\\d+ -\\d+\\.\\d+ 1 \\d+ -\\d+\\.\\d+ \\d+\\.\\d+ \\d+\\.\\d+ 1 \\d+ \\d+\\.\\d+ -\\d+\\.\\d+ \\d+\\.\\d+ 1 \\d+ -\\d+\\.\\d+ -\\d+\\.\\d+ \\d+\\.\\d+ 0 \\[\\d+ rows x 4 columns\\]/"
  - code: Out
  - text: /\(SPURuntime pid=\d+\) \d+-\d+-\d+ \d+:\d+:\d+\.\d+ \[info\] \[default_brpc_retry_policy\.cc:DoRetry:\d+\] socket error, sleep=1000000us and retry/
  - code: Out
  - text: "/\\(_run pid=\\d+\\) \\[\\d+-\\d+-\\d+ \\d+:\\d+:\\d+\\.\\d+\\] \\[info\\] \\[thread_pool\\.cc:\\d+\\] Create a fixed thread pool with size \\d+ \\(SPURuntime pid=\\d+\\) \\d+-\\d+-\\d+ \\d+:\\d+:\\d+\\.\\d+ \\[info\\] \\[default_brpc_retry_policy\\.cc:LogHttpDetail:\\d+\\] cntl ErrorCode '\\d+', http status code '\\d+', response header '', error msg '\\[E111\\]Fail to connect Socket\\{id=0 addr=\\d+\\.\\d+\\.0\\.1:\\d+\\} \\(0x0x32ed440\\): Connection refused \\[R1\\]\\[E112\\]Not connected to \\d+\\.\\d+\\.0\\.1:\\d+ yet, server_id=0' \\(SPURuntime pid=\\d+\\) \\d+-\\d+-\\d+ \\d+:\\d+:\\d+\\.\\d+ \\[info\\] \\[default_brpc_retry_policy\\.cc:DoRetry:\\d+\\] aggressive retry, sleep=1000000us and retry \\(SPURuntime pid=\\d+\\) \\d+-\\d+-\\d+ \\d+:\\d+:\\d+\\.\\d+ \\[info\\] \\[default_brpc_retry_policy\\.cc:DoRetry:\\d+\\] not retry for reached rcp timeout, ErrorCode '\\d+', error msg '\\[E1008\\]Reached timeout=\\d+[hmsp]+ @\\d+\\.\\d+\\.0\\.1:\\d+' \\(SPURuntime pid=\\d+\\) \\d+-\\d+-\\d+ \\d+:\\d+:\\d+\\.\\d+ \\[info\\] \\[default_brpc_retry_policy\\.cc:LogHttpDetail:\\d+\\] cntl ErrorCode '\\d+', http status code '\\d+', response header '', error msg '\\[E111\\]Fail to connect Socket\\{id=0 addr=\\d+\\.\\d+\\.0\\.1:\\d+\\} \\(0x0x32ed440\\): Connection refused \\[R1\\]\\[E112\\]Not connected to \\d+\\.\\d+\\.0\\.1:\\d+ yet, server_id=0 \\[R2\\]\\[E112\\]Not connected to \\d+\\.\\d+\\.0\\.1:\\d+ yet, server_id=0' \\(SPURuntime pid=\\d+\\) \\d+-\\d+-\\d+ \\d+:\\d+:\\d+\\.\\d+ \\[info\\] \\[default_brpc_retry_policy\\.cc:DoRetry:\\d+\\] aggressive retry, sleep=1000000us and retry/"
  - code: Out
  - text: "/\\(SPURuntime\\(device_id=None, party=bob\\) pid=\\d+\\) \\d+-\\d+-\\d+ \\d+:\\d+:\\d+\\.\\d+ \\[info\\] \\[thread_pool\\.cc:ThreadPool:\\d+\\] Create a fixed thread pool with size \\d+ \\(SPURuntime\\(device_id=None, party=alice\\) pid=\\d+\\) \\d+-\\d+-\\d+ \\d+:\\d+:\\d+\\.\\d+ \\[info\\] \\[thread_pool\\.cc:ThreadPool:\\d+\\] Create a fixed thread pool with size \\d+ bin_rules for alice: \\{'variables': \\[\\{'name': 'x1', 'type': 'numeric', 'split_points': \\[-\\d+\\.\\d+, -\\d+\\.\\d+, \\d+\\.\\d+, \\d+\\.\\d+\\], 'filling_values': \\[\\d+\\.\\d+, \\d+\\.\\d+, \\d+\\.\\d+, -\\d+\\.\\d+, -\\d+\\.\\d+\\], 'total_counts': \\[\\d+, \\d+, \\d+, \\d+, \\d+\\], 'else_filling_value': -\\d+\\.\\d+, 'else_counts': 0\\}, \\{'name': 'x2', 'type': 'numeric', 'split_points': \\[-\\d+\\.\\d+, -\\d+\\.\\d+, \\d+\\.\\d+, \\d+\\.\\d+\\], 'filling_values': \\[-\\d+\\.\\d+, -\\d+\\.\\d+, \\d+\\.\\d+, \\d+\\.\\d+, \\d+\\.\\d+\\], 'total_counts': \\[\\d+, \\d+, \\d+, \\d+, \\d+\\], 'else_filling_value': -\\d+\\.\\d+, 'else_counts': 0\\}, \\{'name': 'x3', 'type': 'numeric', 'split_points': \\[-\\d+\\.\\d+, -\\d+\\.\\d+, \\d+\\.\\d+, \\d+\\.\\d+\\], 'filling_values': \\[-\\d+\\.\\d+, -\\d+\\.\\d+, -\\d+\\.\\d+, \\d+\\.\\d+, \\d+\\.\\d+\\], 'total_counts': \\[\\d+, \\d+, \\d+, \\d+, \\d+\\], 'else_filling_value': -\\d+\\.\\d+, 'else_counts': 0\\}\\]\\} bin_rules for bob: \\{'variables': \\[\\{'name': 'x18', 'type': 'numeric', 'split_points': \\[-\\d+\\.\\d+, -\\d+\\.\\d+, \\d+\\.\\d+, \\d+\\.\\d+\\], 'filling_values': \\[\\d+\\.\\d+, \\d+\\.\\d+, \\d+\\.\\d+, -\\d+\\.\\d+, -\\d+\\.\\d+\\], 'total_counts': \\[\\d+, \\d+, \\d+, \\d+, \\d+\\], 'else_filling_value': -\\d+\\.\\d+, 'else_counts': 0\\}, \\{'name': 'x19', 'type': 'numeric', 'split_points': \\[-\\d+\\.\\d+, -\\d+\\.\\d+, \\d+\\.\\d+, \\d+\\.\\d+\\], 'filling_values': \\[-\\d+\\.\\d+, -\\d+\\.\\d+, \\d+\\.\\d+, \\d+\\.\\d+, \\d+\\.\\d+\\], 'total_counts': \\[\\d+, \\d+, \\d+, \\d+, \\d+\\], 'else_filling_value': -\\d+\\.\\d+, 'else_counts': 0\\}, \\{'name': 'x20', 'type': 'numeric', 'split_points': \\[-\\d+\\.\\d+, -\\d+\\.\\d+, \\d+\\.\\d+, \\d+\\.\\d+\\], 'filling_values': \\[\\d+\\.\\d+, \\d+\\.\\d+, \\d+\\.\\d+, -\\d+\\.\\d+, -\\d+\\.\\d+\\], 'total_counts': \\[\\d+, \\d+, \\d+, \\d+, \\d+\\], 'else_filling_value': -\\d+\\.\\d+, 'else_counts': 0\\}\\], 'feature_iv_info': \\[\\{'name': 'x18', 'ivs': \\(\\d+\\.\\d+, \\d+\\.\\d+, \\d+\\.\\d+, \\d+\\.\\d+, \\d+\\.\\d+\\), 'else_iv': 6\\.385923806287768e-\\d+, 'feature_iv': \\d+\\.\\d+\\}, \\{'name': 'x19', 'ivs': \\(\\d+\\.\\d+, \\d+\\.\\d+, \\d+\\.\\d+, \\d+\\.\\d+, \\d+\\.\\d+\\), 'else_iv': 6\\.385923806287768e-\\d+, 'feature_iv': \\d+\\.\\d+\\}, \\{'name': 'x20', 'ivs': \\(\\d+\\.\\d+, \\d+\\.\\d+, \\d+\\.\\d+, \\d+\\.\\d+, \\d+\\.\\d+\\), 'else_iv': 6\\.385923806287768e-\\d+, 'feature_iv': \\d+\\.\\d+\\}, \\{'name': 'x1', 'ivs': \\(\\d+\\.\\d+, \\d+\\.\\d+, 3\\.104792224414912e-\\d+, \\d+\\.\\d+, \\d+\\.\\d+\\), 'else_iv': 6\\.385923806287768e-\\d+, 'feature_iv': \\d+\\.\\d+\\}, \\{'name': 'x2', 'ivs': \\(\\d+\\.\\d+, \\d+\\.\\d+, 9\\.424153452104671e-\\d+, \\d+\\.\\d+, \\d+\\.\\d+\\), 'else_iv': 6\\.385923806287768e-\\d+, 'feature_iv': \\d+\\.\\d+\\}, \\{'name': 'x3', 'ivs': \\(\\d+\\.\\d+, \\d+\\.\\d+, 9\\.751520288052276e-\\d+, \\d+\\.\\d+, \\d+\\.\\d+\\), 'else_iv': 6\\.385923806287768e-\\d+, 'feature_iv': \\d+\\.\\d+\\}\\]\\} substituted ds in alice: x1 x2 x3 0 \\d+\\.\\d+ \\d+\\.\\d+ -\\d+\\.\\d+ 1 \\d+\\.\\d+ \\d+\\.\\d+ -\\d+\\.\\d+ 2 -\\d+\\.\\d+ \\d+\\.\\d+ -\\d+\\.\\d+ 3 \\d+\\.\\d+ \\d+\\.\\d+ \\d+\\.\\d+ 4 \\d+\\.\\d+ \\d+\\.\\d+ \\d+\\.\\d+ \\.\\.\\. \\.\\.\\. \\.\\.\\. \\.\\.\\. \\d+ \\d+\\.\\d+ -\\d+\\.\\d+ \\d+\\.\\d+ \\d+ \\d+\\.\\d+ \\d+\\.\\d+ -\\d+\\.\\d+ \\d+ \\d+\\.\\d+ \\d+\\.\\d+ -\\d+\\.\\d+ \\d+ -\\d+\\.\\d+ -\\d+\\.\\d+ \\d+\\.\\d+ \\d+ \\d+\\.\\d+ -\\d+\\.\\d+ -\\d+\\.\\d+ \\[\\d+ rows x 3 columns\\] substituted ds in bob: x18 x19 x20 y 0 -\\d+\\.\\d+ \\d+\\.\\d+ -\\d+\\.\\d+ 1 1 -\\d+\\.\\d+ \\d+\\.\\d+ -\\d+\\.\\d+ 1 2 \\d+\\.\\d+ -\\d+\\.\\d+ -\\d+\\.\\d+ 0 3 \\d+\\.\\d+ \\d+\\.\\d+ -\\d+\\.\\d+ 1 4 \\d+\\.\\d+ \\d+\\.\\d+ \\d+\\.\\d+ 1 \\.\\.\\. \\.\\.\\. \\.\\.\\. \\.\\.\\. \\.\\. \\d+ \\d+\\.\\d+ \\d+\\.\\d+ -\\d+\\.\\d+ 1 \\d+ \\d+\\.\\d+ \\d+\\.\\d+ \\d+\\.\\d+ 1 \\d+ \\d+\\.\\d+ \\d+\\.\\d+ -\\d+\\.\\d+ 1 \\d+ -\\d+\\.\\d+ -\\d+\\.\\d+ -\\d+\\.\\d+ 1 \\d+ \\d+\\.\\d+ \\d+\\.\\d+ -\\d+\\.\\d+ 0 \\[\\d+ rows x 4 columns\\]/"
  - heading "Ending" [level=2]:
    - link "Direct link to Ending":
      - /url: "#Ending"
  - code: /In \[\d+\]:/
  - button "Copy":
    - img "copy"
  - code: python
  - code: "# Clean up temporary files import os try: os.remove(alice_path) os.remove(bob_path) except OSError: pass"