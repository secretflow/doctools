- article:
  - heading "Federated Learning for Image Classification" [level=1]:
    - link "Direct link to Federated Learning for Image Classification":
      - /url: "#Federated-Learning-for-Image-Classification"
  - blockquote:
    - paragraph:
      - text: The following codes are demos only. It’s
      - strong: NOT for production
      - text: due to system security concerns, please
      - strong: DO NOT
      - text: use it directly in production.
  - paragraph:
    - text: In this tutorial, we will use the image classification task to show how to complete the horizontal federated learning task in the
    - code: SecretFlow
    - text: framework. The
    - code: SecretFlow
    - text: framework provides a user-friendly API that makes it easy to apply your Keras or PyTorch model to a federated learning scenario as a federated learning model. In the rest of the tutorial we will show you how to turn your existing model into a federated model in
    - code: SecretFlow
    - text: to complete federated multi-party modeling tasks.
  - heading "What is Federated Learning" [level=2]:
    - link "Direct link to What is Federated Learning":
      - /url: "#What-is-Federated-Learning"
  - paragraph: The federated learning discussed here is specifically focused on horizontal scenarios, where each participant shares the same business but reaches different customer groups. This allows samples from different parties to be combined to train a joint model with improved performance. An example of this scenario can be found in the medical field, where each hospital has its own distinctive patient group and hospitals in different regions largely do not overlap. However, their medical records (such as images and blood tests) for diagnostic purposes are of the same type.
  - paragraph:
    - img
  - paragraph: "Training process:"
  - list:
    - listitem: Each participant downloads the latest model from the server.
    - listitem: Each participant uses its own local data to train the model, and uploads gradient encryption (or parameter encryption) to the server, which obtains the encryption gradient (encryption parameter) uploaded by all parties for security aggregation at the server, and updates model parameters with the aggregated gradient.
    - listitem: The server returns the updated model to each participant.
    - listitem: Each participant updates their local model, and prepare next training.
  - heading "Federated learning on SecretFlow" [level=2]:
    - link "Direct link to Federated learning on SecretFlow":
      - /url: "#Federated-learning-on-SecretFlow"
  - code: "In [1]:"
  - button "Copy":
    - img "copy"
  - code: python
  - code: "%load_ext autoreload %autoreload 2"
  - paragraph: Create 3 entities in the Secretflow environment [Alice, Bob, Charlie]. Alice, Bob and Charlie are the three PYUs. Alice and Bob to be the clients and Charlie to be the server.
  - code: "In [2]:"
  - button "Copy":
    - img "copy"
  - code: python
  - code: "import secretflow as sf # Check the version of your SecretFlow print('The version of SecretFlow: {}'.format(sf.__version__)) # In case you have a running secretflow runtime already. sf.shutdown() sf.init(['alice', 'bob', 'charlie'], address='local') alice, bob, charlie = sf.PYU('alice'), sf.PYU('bob'), sf.PYU('charlie')"
  - code: Out
  - text: "The version of SecretFlow: 1.5.0.dev20240304"
  - code: "In [3]:"
  - button "Copy":
    - img "copy"
  - code: spu = sf.SPU(sf.utils.testing.cluster_def(['alice', 'bob']))
  - heading "Prepare Data" [level=3]:
    - link "Direct link to Prepare Data":
      - /url: "#Prepare-Data"
  - paragraph: Alice and Bob each own half the data.
  - code: "In [4]:"
  - button "Copy":
    - img "copy"
  - code: python
  - code: "/from secretflow_fl\\.utils\\.simulation\\.datasets_fl import load_mnist \\(x_train, y_train\\), \\(x_test, y_test\\) = load_mnist\\( parts=\\{alice: \\d+\\.\\d+, bob: \\d+\\.\\d+\\}, normalized_x=True, categorical_y=True, is_torch=False, \\)/"
  - paragraph:
    - code: x_train
    - text: ","
    - code: y_train
    - text: ","
    - code: x_test
    - text: ","
    - code: y_test
    - text: are both
    - code: FedNdarray
    - text: . Let’s take a look at the data obtained from FedNdarray. FedNdarray is a virtual Ndarray built on a multi-party concept to protect data privacy. The underlying data is stored in each participant. The FedNdarray operation is actually performed by each participant on their own local data. The server or other clients do not touch the original data. For demonstration purposes, we will manually download the data to the driver.
    - strong: This data will be used later in the unilateral model comparison
    - text: .
  - code: "In [5]:"
  - button "Copy":
    - img "copy"
  - code: python
  - code: import numpy as np from secretflow.utils.simulation.datasets import dataset mnist = np.load(dataset('mnist'), allow_pickle=True) image = mnist['x_train'] label = mnist['y_train']
  - paragraph: Let’s grab some samples from the data set, and just visually see, what does the data look like for Both Alice and Bob?
  - code: "In [6]:"
  - button "Copy":
    - img "copy"
  - code: python
  - code: "/from matplotlib import pyplot as plt figure = plt\\.figure\\(figsize=\\(\\d+, 4\\)\\) j = 0 for example in image\\[:\\d+\\]: plt\\.subplot\\(4, \\d+, j \\+ 1\\) plt\\.imshow\\(example, cmap='gray', aspect='equal'\\) plt\\.axis\\('off'\\) j \\+= 1/"
  - code: Out
  - paragraph:
    - img
  - code: "In [7]:"
  - button "Copy":
    - img "copy"
  - code: python
  - code: "/figure = plt\\.figure\\(figsize=\\(\\d+, 4\\)\\) j = 0 for example in image\\[\\d+:\\d+\\]: plt\\.subplot\\(4, \\d+, j \\+ 1\\) plt\\.imshow\\(example, cmap='gray', aspect='equal'\\) plt\\.axis\\('off'\\) j \\+= 1/"
  - code: Out
  - paragraph:
    - img
  - paragraph: It can be seen from the above two examples that the data types and tasks of Alice and Bob are consistent, but the samples are different due to the different user groups they reach.
  - heading "Define Model" [level=3]:
    - link "Direct link to Define Model":
      - /url: "#Define-Model"
  - code: "In [8]:"
  - button "Copy":
    - img "copy"
  - code: python
  - code: "/def create_conv_model\\(input_shape, num_classes, name='model'\\): def create_model\\(\\): from tensorflow import keras from tensorflow\\.keras import layers # Create model model = keras\\.Sequential\\( \\[ keras\\.Input\\(shape=input_shape\\), layers\\.Conv2D\\(\\d+, kernel_size=\\(3, 3\\), activation=\"relu\"\\), layers\\.MaxPooling2D\\(pool_size=\\(2, 2\\)\\), layers\\.Conv2D\\(\\d+, kernel_size=\\(3, 3\\), activation=\"relu\"\\), layers\\.MaxPooling2D\\(pool_size=\\(2, 2\\)\\), layers\\.Flatten\\(\\), layers\\.Dropout\\(0\\.5\\), layers\\.Dense\\(num_classes, activation=\"softmax\"\\), \\] \\) # Compile model model\\.compile\\( loss='categorical_crossentropy', optimizer='adam', metrics=\\[\"accuracy\"\\] \\) return model return create_model/"
  - heading "Training FL Model" [level=3]:
    - link "Direct link to Training FL Model":
      - /url: "#Training-FL-Model"
  - list:
    - listitem: Import packages
  - code: "In [9]:"
  - button "Copy":
    - img "copy"
  - code: python
  - code: from secretflow.security.aggregation import SPUAggregator, SecureAggregator from secretflow_fl.ml.nn import FLModel
  - list:
    - listitem: Define Model
  - code: /In \[\d+\]:/
  - button "Copy":
    - img "copy"
  - code: python
  - code: /num_classes = \d+ input_shape = \(\d+, \d+, 1\) model = create_conv_model\(input_shape, num_classes\)/
  - list:
    - listitem: Define the device list for participating training, which is the PYUS of each participant prepared previously.
  - code: /In \[\d+\]:/
  - button "Copy":
    - img "copy"
  - code: device_list = [alice, bob]
  - list:
    - listitem:
      - text: Define Aggregator The SecretFlow framework provides a variety of aggregation schemes, including
      - code: SecureAggregator
      - text: and
      - code: PPUAggregator
      - text: ", which can be used for secure aggregation. To learn more information about aggregation, see"
      - link "Secure Aggregator":
        - /url: /en/docs/secretflow/v1.12.0b0/developer/algorithm/secure_aggregation
      - text: .
  - code: /In \[\d+\]:/
  - button "Copy":
    - img "copy"
  - code: python
  - code: secure_aggregator = SecureAggregator(charlie, [alice, bob]) spu_aggregator = SPUAggregator(spu)
  - list:
    - listitem: Define FLModel
  - code: /In \[\d+\]:/
  - button "Copy":
    - img "copy"
  - code: python
  - code: fed_model = FLModel( server=charlie, device_list=device_list, model=model, aggregator=secure_aggregator, strategy="fed_avg_w", backend="tensorflow", )
  - list:
    - listitem: Lets run model
  - code: /In \[\d+\]:/
  - button "Copy":
    - img "copy"
  - code: python
  - code: /history = fed_model\.fit\( x_train, y_train, validation_data=\(x_test, y_test\), epochs=\d+, sampler_method="batch", batch_size=\d+, aggregate_freq=1, \)/
  - code: Out
  - text: /Epoch 1\/\d+/
  - code: Out
  - text: /Epoch 2\/\d+/
  - code: Out
  - text: /Epoch 3\/\d+/
  - code: Out
  - text: /Epoch 4\/\d+/
  - code: Out
  - text: /Epoch 5\/\d+/
  - code: Out
  - text: /Epoch 6\/\d+/
  - code: Out
  - text: /Epoch 7\/\d+/
  - code: Out
  - text: /Epoch 8\/\d+/
  - code: Out
  - text: /Epoch 9\/\d+/
  - code: Out
  - text: /Epoch \d+\/\d+/
  - code: /In \[\d+\]:/
  - button "Copy":
    - img "copy"
  - code: python
  - code: "# Draw accuracy values for training & validation plt.plot(history[\"global_history\"]['accuracy']) plt.plot(history[\"global_history\"]['val_accuracy']) plt.title('FLModel accuracy') plt.ylabel('Accuracy') plt.xlabel('Epoch') plt.legend(['Train', 'Valid'], loc='upper left') plt.show() # Draw loss for training & validation plt.plot(history[\"global_history\"]['loss']) plt.plot(history[\"global_history\"]['val_loss']) plt.title('FLModel loss') plt.ylabel('Loss') plt.xlabel('Epoch') plt.legend(['Train', 'Valid'], loc='upper left') plt.show()"
  - code: Out
  - paragraph:
    - img
  - code: Out
  - paragraph:
    - img
  - code: /In \[\d+\]:/
  - button "Copy":
    - img "copy"
  - code: python
  - code: /global_metric = fed_model\.evaluate\(x_test, y_test, batch_size=\d+\) print\(global_metric\)/
  - code: Out
  - text: "/\\(\\[Mean\\(name='val_loss', total=\\d+\\.\\d+, count=\\d+\\.\\d+\\), Mean\\(name='val_accuracy', total=\\d+\\.\\d+, count=\\d+\\.\\d+\\)\\], \\{'alice': \\[Mean\\(name='val_loss', total=\\d+\\.\\d+, count=\\d+\\.\\d+\\), Mean\\(name='val_accuracy', total=\\d+\\.\\d+, count=\\d+\\.\\d+\\)\\], 'bob': \\[Mean\\(name='val_loss', total=\\d+\\.\\d+, count=\\d+\\.\\d+\\), Mean\\(name='val_accuracy', total=\\d+\\.\\d+, count=\\d+\\.\\d+\\)\\]\\}\\)/"
  - heading "Contrast experiment to local training" [level=3]:
    - link "Direct link to Contrast experiment to local training":
      - /url: "#Contrast-experiment-to-local-training"
  - heading "Model" [level=4]:
    - link "Direct link to Model":
      - /url: "#Model"
  - paragraph: The model structure is consistent with the fl model above.
  - heading "Data" [level=4]:
    - link "Direct link to Data":
      - /url: "#Data"
  - paragraph:
    - text: /Here, we only used data after a horizontal segmentation, with a total of \d+,\d+ samples for/
    - code: Alice
    - text: .
  - code: /In \[\d+\]:/
  - button "Copy":
    - img "copy"
  - code: python
  - code: "/from tensorflow import keras from tensorflow\\.keras import layers def create_model\\(\\): model = keras\\.Sequential\\( \\[ keras\\.Input\\(shape=input_shape\\), layers\\.Conv2D\\(\\d+, kernel_size=\\(3, 3\\), activation=\"relu\"\\), layers\\.MaxPooling2D\\(pool_size=\\(2, 2\\)\\), layers\\.Conv2D\\(\\d+, kernel_size=\\(3, 3\\), activation=\"relu\"\\), layers\\.MaxPooling2D\\(pool_size=\\(2, 2\\)\\), layers\\.Flatten\\(\\), layers\\.Dropout\\(0\\.5\\), layers\\.Dense\\(num_classes, activation=\"softmax\"\\), \\] \\) # Compile model model\\.compile\\( loss='categorical_crossentropy', optimizer='adam', metrics=\\[\"accuracy\"\\] \\) return model single_model = create_model\\(\\)/"
  - code: /In \[\d+\]:/
  - button "Copy":
    - img "copy"
  - code: mnist.files
  - code: /Out \[\d+\]:/
  - text: "['x_test', 'x_train', 'y_train', 'y_test']"
  - code: /In \[\d+\]:/
  - button "Copy":
    - img "copy"
  - code: python
  - code: /from sklearn\.model_selection import train_test_split from sklearn\.preprocessing import OneHotEncoder alice_x = image\[:\d+\] alice_y = label\[:\d+\] alice_y = OneHotEncoder\(sparse_output=False\)\.fit_transform\(alice_y\.reshape\(-1, 1\)\) random_seed = \d+ alice_X_train, alice_X_test, alice_y_train, alice_y_test = train_test_split\( alice_x, alice_y, test_size=0\.1, random_state=random_seed \)/
  - code: /In \[\d+\]:/
  - button "Copy":
    - img "copy"
  - code: python
  - code: /single_model\.fit\( alice_X_train, alice_y_train, validation_data=\(alice_X_test, alice_y_test\), batch_size=\d+, epochs=\d+, \)/
  - code: Out
  - text: "/Epoch 1\\/\\d+ \\d+\\/\\d+ \\[====>\\.\\.\\.\\.\\.\\.\\.\\.\\.\\.\\.\\.\\.\\.\\.\\.\\.\\.\\.\\.\\.\\.\\.\\.\\.\\] - ETA: \\d+[hmsp]+ - loss: \\d+\\.\\d+ - accuracy: \\d+\\.\\d+\\/\\d+ \\[==============================\\] - \\d+[hmsp]+ \\d+[hmsp]+\\/step - loss: \\d+\\.\\d+ - accuracy: \\d+\\.\\d+ - val_loss: \\d+\\.\\d+ - val_accuracy: \\d+\\.\\d+ Epoch 2\\/\\d+ \\d+\\/\\d+ \\[==============================\\] - \\d+[hmsp]+ \\d+[hmsp]+\\/step - loss: \\d+\\.\\d+ - accuracy: \\d+\\.\\d+ - val_loss: \\d+\\.\\d+ - val_accuracy: \\d+\\.\\d+ Epoch 3\\/\\d+ \\d+\\/\\d+ \\[==============================\\] - \\d+[hmsp]+ \\d+[hmsp]+\\/step - loss: \\d+\\.\\d+ - accuracy: \\d+\\.\\d+ - val_loss: \\d+\\.\\d+ - val_accuracy: \\d+\\.\\d+ Epoch 4\\/\\d+ \\d+\\/\\d+ \\[==============================\\] - \\d+[hmsp]+ \\d+[hmsp]+\\/step - loss: \\d+\\.\\d+ - accuracy: \\d+\\.\\d+ - val_loss: \\d+\\.\\d+ - val_accuracy: \\d+\\.\\d+ Epoch 5\\/\\d+ \\d+\\/\\d+ \\[==============================\\] - \\d+[hmsp]+ \\d+[hmsp]+\\/step - loss: \\d+\\.\\d+ - accuracy: \\d+\\.\\d+ - val_loss: \\d+\\.\\d+ - val_accuracy: \\d+\\.\\d+ Epoch 6\\/\\d+ \\d+\\/\\d+ \\[==============================\\] - \\d+[hmsp]+ \\d+[hmsp]+\\/step - loss: \\d+\\.\\d+ - accuracy: \\d+\\.\\d+ - val_loss: \\d+\\.\\d+ - val_accuracy: \\d+\\.\\d+ Epoch 7\\/\\d+ \\d+\\/\\d+ \\[==============================\\] - \\d+[hmsp]+ \\d+[hmsp]+\\/step - loss: \\d+\\.\\d+ - accuracy: \\d+\\.\\d+ - val_loss: \\d+\\.\\d+ - val_accuracy: \\d+\\.\\d+ Epoch 8\\/\\d+ \\d+\\/\\d+ \\[==============================\\] - \\d+[hmsp]+ \\d+[hmsp]+\\/step - loss: \\d+\\.\\d+ - accuracy: \\d+\\.\\d+ - val_loss: \\d+\\.\\d+ - val_accuracy: \\d+\\.\\d+ Epoch 9\\/\\d+ \\d+\\/\\d+ \\[==============================\\] - \\d+[hmsp]+ \\d+[hmsp]+\\/step - loss: \\d+\\.\\d+ - accuracy: \\d+\\.\\d+ - val_loss: \\d+\\.\\d+ - val_accuracy: \\d+\\.\\d+ Epoch \\d+\\/\\d+ \\d+\\/\\d+ \\[==============================\\] - \\d+[hmsp]+ \\d+[hmsp]+\\/step - loss: \\d+\\.\\d+ - accuracy: \\d+\\.\\d+ - val_loss: \\d+\\.\\d+ - val_accuracy: \\d+\\.\\d+/"
  - code: /Out \[\d+\]:/
  - text: <keras.callbacks.History at 0x7fd6dc54d390>
  - paragraph: /The two experiments above simulated a training problem in a typical horizontal federation scenario, Alice and Bob have same type of data\. Each side had only a portion of the sample, but the training objectives is the same\. If Alice only uses her own data to train the model, could only obtain a model with an accuracy of \d+\.\d+\. However, if Bob’s data is combined, a model with an accuracy close to \d+\.\d+ can be obtained\. In addition, the generalization performance of the model jointly trained with multi-party data will also be better\./
  - heading "Conclusion" [level=2]:
    - link "Direct link to Conclusion":
      - /url: "#Conclusion"
  - list:
    - listitem:
      - text: This tutorial introduces what federated learning is and how to perform horizontal federated learning in
      - code: secretFlow
      - text: .
    - listitem: It can be seen from the experimental data that horizontal federation can improve the model effect by expanding the sample size and combining multi-party training.
    - listitem:
      - text: This tutorial uses a SecureAggregator to demonstrate, and secretflow provides a variety of aggregation schemes，for more infomation, see
      - link "Secure Aggregation":
        - /url: /en/docs/secretflow/v1.12.0b0/developer/algorithm/secure_aggregation
      - text: .
    - listitem: next, you can use your data or model to explore how to do federate learning.